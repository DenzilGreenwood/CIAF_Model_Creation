# Singapore Model AI Governance Framework - Regulatory Summary

**Document Version:** 1.0  
**Date:** October 18, 2025  
**Framework Status:** Second Edition (January 2020), Generative AI Update (May 2024)  
**Official Sources:** 
- [PDPC - Model AI Governance Framework](https://www.pdpc.gov.sg/help-and-resources/2020/01/second-edition-of-model-artificial-intelligence-governance-framework)
- [AI Verify Foundation - Generative AI Framework](https://aiverifyfoundation.sg/wp-content/uploads/2024/05/Model-AI-Governance-Framework-for-Generative-AI-May-2024-1-1.pdf)

---

## Framework Overview

Singapore's Model AI Governance Framework represents a pioneering approach to AI governance, emphasizing practical guidance for organizations deploying AI systems. Developed through extensive industry consultation, the framework provides voluntary, sector-agnostic guidance that balances innovation promotion with risk management across the AI lifecycle.

### Design Philosophy

The framework is built on several core principles:
- **Voluntary adoption:** Non-mandatory guidance that organizations can adapt to their specific contexts
- **Practical orientation:** Focus on actionable recommendations rather than abstract principles
- **Innovation-friendly:** Designed to enable responsible innovation while managing risks
- **Adaptable approach:** Flexible framework that can be tailored to different industries and use cases

---

## Core Framework Structure (2020 Edition)

The framework is organized around four key dimensions that address the entire AI lifecycle:

### 1. Internal Governance Structures and Measures

#### Governance Framework Development
- **AI governance policies:** Establish clear organizational policies for AI development and deployment
- **Risk management integration:** Incorporate AI risks into existing enterprise risk management frameworks
- **Stakeholder engagement:** Define processes for involving relevant stakeholders in AI governance decisions
- **Accountability mechanisms:** Establish clear roles and responsibilities for AI system oversight

#### Organizational Capabilities
- **Competency development:** Build internal capabilities for responsible AI development and deployment
- **Cross-functional coordination:** Establish collaboration between technical, legal, business, and ethics teams
- **Decision-making processes:** Create structured approaches for AI system approval and oversight
- **Cultural integration:** Embed responsible AI practices into organizational culture and values

### 2. Determining the Level of Human Involvement in AI-Augmented Decision-Making

#### Human-AI Interaction Design
- **Human oversight levels:** Determine appropriate degrees of human involvement based on decision impact and risk
- **Control mechanisms:** Implement systems for human override and intervention in AI decision-making
- **Competency requirements:** Ensure human operators have necessary skills and knowledge for effective oversight
- **Feedback systems:** Establish mechanisms for incorporating human insights into AI system improvement

#### Decision Classification Framework
- **Impact assessment:** Evaluate the significance of decisions made by or with AI systems
- **Risk-based categorization:** Classify decisions based on potential consequences and required oversight levels
- **Contextual considerations:** Account for specific operational contexts and stakeholder impacts
- **Dynamic adjustment:** Allow for modification of oversight levels based on system performance and changing risks

### 3. Operations Management

#### Lifecycle Management
- **Development governance:** Oversight of AI system design, training, and testing phases
- **Deployment controls:** Systematic approaches to AI system implementation and rollout
- **Performance monitoring:** Ongoing assessment of AI system behavior and outcomes
- **Maintenance and updates:** Procedures for system updates, retraining, and lifecycle management

#### Risk Management Integration
- **Risk identification:** Systematic identification of AI-related risks across the operational lifecycle
- **Mitigation strategies:** Implementation of technical and procedural controls to address identified risks
- **Incident response:** Procedures for addressing AI system failures, errors, or unexpected behavior
- **Continuous improvement:** Regular review and enhancement of operational practices based on experience

### 4. Stakeholder Interaction and Communication

#### Transparency and Disclosure
- **Public communication:** Clear communication about AI system use and capabilities to relevant stakeholders
- **User information:** Appropriate disclosure to users about AI involvement in decisions affecting them
- **Limitation acknowledgment:** Honest communication about AI system limitations and uncertainty
- **Redress mechanisms:** Processes for stakeholders to raise concerns or seek recourse for AI-related issues

#### Engagement Processes
- **Stakeholder identification:** Systematic identification of parties affected by or interested in AI deployments
- **Consultation methods:** Appropriate approaches for engaging different stakeholder groups
- **Feedback incorporation:** Mechanisms for considering and responding to stakeholder input
- **Ongoing dialogue:** Establishment of continuing engagement processes rather than one-time consultations

---

## Generative AI Framework Update (2024)

The Model AI Governance Framework for Generative AI addresses specific challenges and opportunities presented by generative AI technologies:

### Enhanced Governance Dimensions

#### 1. Accountability and Governance
- **Clear ownership:** Establishment of clear responsibility for generative AI system governance and oversight
- **Risk-based governance:** Governance structures proportionate to the risks and impacts of generative AI systems
- **Multi-stakeholder engagement:** Involvement of diverse perspectives in generative AI governance decisions
- **Regulatory alignment:** Coordination with applicable legal and regulatory requirements

#### 2. Data Management and Quality
- **Training data governance:** Comprehensive management of data used to train generative AI models
- **Data quality assurance:** Processes to ensure training data quality, representativeness, and appropriateness
- **Bias mitigation:** Systematic approaches to identify and address biases in training datasets
- **Intellectual property compliance:** Respect for copyright and other IP rights in training data

#### 3. Model Development and Validation
- **Development standards:** Application of rigorous engineering standards to generative AI model development
- **Testing and validation:** Comprehensive evaluation of model performance, safety, and reliability
- **Red team exercises:** Adversarial testing to identify potential misuse scenarios and vulnerabilities
- **Documentation requirements:** Comprehensive documentation of model capabilities, limitations, and intended uses

#### 4. Deployment and Monitoring
- **Safe deployment:** Careful planning and execution of generative AI system deployment
- **Real-time monitoring:** Continuous oversight of system performance and behavior in production
- **User feedback integration:** Mechanisms for incorporating user feedback into system operation and improvement
- **Incident response:** Procedures for addressing problems, errors, or unexpected behavior in deployed systems

#### 5. Human Oversight and Control
- **Meaningful human control:** Ensuring appropriate human oversight of generative AI system operation
- **Override capabilities:** Technical and procedural mechanisms for human intervention in system operation
- **Competency requirements:** Ensuring human operators have necessary skills for effective oversight
- **Escalation procedures:** Clear processes for escalating issues requiring human judgment or intervention

#### 6. Transparency and Explainability
- **Output attribution:** Clear identification of AI-generated content and its sources
- **Process transparency:** Appropriate disclosure of how generative AI systems operate and make decisions
- **Limitation communication:** Clear communication of system limitations and potential errors
- **User education:** Helping users understand how to interact appropriately with generative AI systems

#### 7. Content Integrity and Authenticity
- **Content provenance:** Systems for tracking and verifying the origins of generated content
- **Watermarking and labeling:** Technical and procedural measures to identify AI-generated content
- **Misinformation prevention:** Measures to reduce the risk of generating false or misleading information
- **Quality control:** Ongoing assessment and improvement of generated content quality

#### 8. User Safety and Well-being
- **Harm prevention:** Measures to prevent generation of harmful, dangerous, or inappropriate content
- **Vulnerable population protection:** Special considerations for protecting children, elderly, and other vulnerable users
- **Mental health considerations:** Awareness of potential psychological impacts of generative AI interactions
- **User empowerment:** Tools and information to help users make informed decisions about AI use

#### 9. Incident Reporting and Response
- **Incident classification:** Clear categorization of different types of problems or failures with generative AI systems
- **Reporting procedures:** Systematic approaches to documenting and communicating incidents
- **Response protocols:** Structured procedures for addressing different types of incidents
- **Learning integration:** Processes for incorporating lessons learned from incidents into system improvement

---

## Sectoral Implementation Guidance

### Financial Services (MAS FEAT Principles)

The Monetary Authority of Singapore has developed specific guidance for AI in financial services through the FEAT (Fairness, Ethics, Accountability, Transparency) principles:

#### Fairness
- **Bias prevention:** Systematic measures to prevent unfair discrimination in financial AI applications
- **Equal treatment:** Ensuring fair treatment of all customers regardless of personal characteristics
- **Inclusive design:** Designing financial AI systems to serve diverse customer populations
- **Outcome monitoring:** Regular assessment of AI system impacts across different customer groups

#### Ethics  
- **Value alignment:** Ensuring AI systems align with ethical principles and organizational values
- **Customer welfare:** Prioritizing customer interests and well-being in AI system design and deployment
- **Professional standards:** Adherence to established financial services professional and ethical standards
- **Stakeholder consideration:** Balancing interests of customers, shareholders, and broader society

#### Accountability
- **Clear responsibility:** Establishing clear ownership and accountability for AI system decisions and outcomes
- **Governance oversight:** Appropriate board and senior management oversight of AI initiatives
- **Risk management:** Integration of AI risks into comprehensive enterprise risk management frameworks
- **Performance monitoring:** Ongoing assessment of AI system performance and impact

#### Transparency
- **Customer communication:** Clear communication to customers about AI use in financial services
- **Regulatory reporting:** Appropriate disclosure to regulators about AI system risks and controls
- **Internal transparency:** Clear documentation and communication of AI system operation within organizations
- **Public accountability:** Appropriate public disclosure of AI governance approaches and outcomes

---

## Implementation Support Resources

### AI Verify Testing Framework

Singapore has developed AI Verify as a complementary technical framework for testing AI systems:

#### Testing Dimensions
- **Performance accuracy:** Evaluation of AI system accuracy and reliability
- **Fairness assessment:** Testing for bias and discriminatory outcomes
- **Explainability evaluation:** Assessment of system transparency and interpretability
- **Robustness testing:** Evaluation of system performance under varied conditions

#### Implementation Tools
- **Automated testing:** Technical tools for systematic evaluation of AI system performance
- **Benchmarking:** Comparative assessment of AI systems against established standards
- **Certification support:** Technical validation to support governance and compliance processes
- **Continuous monitoring:** Ongoing assessment capabilities for deployed AI systems

### Industry Collaboration Initiatives

#### Public-Private Partnerships
- **Industry working groups:** Collaborative development of sector-specific AI governance guidance
- **Research initiatives:** Joint research projects on AI governance challenges and solutions
- **Standards development:** Participation in national and international AI standards development
- **Capacity building:** Training and education programs for AI governance capabilities

#### International Cooperation
- **Global standards alignment:** Coordination with international AI governance frameworks and standards
- **Cross-border collaboration:** Cooperation with other countries on AI governance approaches
- **Regulatory coordination:** Alignment with international regulatory developments
- **Knowledge sharing:** Participation in global AI governance research and policy communities

---

## Implementation Recommendations

### Getting Started with the Framework

#### Organizational Assessment
1. **Current state evaluation:** Assess existing AI governance capabilities and practices
2. **Risk profiling:** Identify and prioritize AI-related risks in your organizational context
3. **Stakeholder mapping:** Identify internal and external stakeholders affected by AI deployments
4. **Regulatory landscape analysis:** Understand applicable legal and regulatory requirements

#### Framework Adaptation
1. **Contextual tailoring:** Adapt framework recommendations to your specific industry and use cases
2. **Risk-based prioritization:** Focus initial efforts on highest-risk AI applications
3. **Phased implementation:** Develop a staged approach to implementing governance measures
4. **Resource planning:** Ensure adequate resources for effective framework implementation

### Building Governance Capabilities

#### Organizational Development
1. **Governance structure:** Establish clear AI governance roles and responsibilities
2. **Policy development:** Create organizational policies for AI development and deployment
3. **Training programs:** Build internal capabilities for responsible AI practices
4. **Cultural change:** Embed responsible AI principles into organizational culture and decision-making

#### Technical Implementation
1. **System documentation:** Establish comprehensive documentation of AI systems and their governance
2. **Monitoring capabilities:** Implement technical and procedural monitoring of AI system performance
3. **Testing frameworks:** Develop systematic approaches to AI system testing and validation
4. **Incident response:** Create procedures for addressing AI system problems and failures

### Sustaining Implementation

#### Continuous Improvement
1. **Regular review:** Periodic assessment and enhancement of AI governance practices
2. **Stakeholder feedback:** Ongoing engagement with stakeholders to gather input and address concerns
3. **Regulatory updates:** Monitoring and adaptation to evolving regulatory requirements
4. **Industry engagement:** Participation in industry initiatives and best practice development

#### Innovation Balance
1. **Risk proportionality:** Ensure governance measures are proportionate to actual risks
2. **Innovation enablement:** Avoid unnecessary barriers to beneficial AI innovation
3. **Competitive advantage:** Leverage responsible AI practices as a competitive differentiator
4. **Market leadership:** Contribute to industry leadership in responsible AI development and deployment

---

**Document Control:**
- **Document Owner:** CIAF Singapore Regulatory Team
- **Next Review Date:** May 18, 2026 (Framework update cycle)
- **Related Documents:** MAS FEAT Principles, AI Verify Technical Framework
- **Version History:** v1.0 - Initial summary (October 18, 2025)