# Colorado AI Act (SB24-205) - Regulatory Summary

**Document Version:** 1.0  
**Date:** October 18, 2025  
**Regulation Status:** Effective February 1, 2026  
**Official Source:** [Colorado General Assembly](https://leg.colorado.gov/bills/sb24-205)

---

## Legislative Overview

The Colorado AI Act (Senate Bill 24-205) represents the first comprehensive state-level AI regulation in the United States, establishing requirements for developers and deployers of high-risk artificial intelligence systems operating in Colorado.

### Scope & Purpose

The Act aims to protect Colorado consumers from algorithmic discrimination while promoting innovation in AI development. It establishes a "reasonable care" standard for AI system development and deployment, focusing on preventing discriminatory outcomes in consequential decisions affecting Colorado residents.

---

## Key Definitions

### High-Risk Artificial Intelligence System
An AI system that, when deployed, makes or is a substantial factor in making a consequential decision. The Act provides specific criteria for determining when an AI system qualifies as "high-risk."

### Consequential Decision
A decision that has a material impact on access to or the cost, terms, or availability of:
- Education enrollment or opportunity
- Employment or employment opportunity
- Financial or lending services
- Essential government services
- Healthcare services
- Housing
- Insurance
- Legal services

### Developer
Any person doing business in Colorado that develops or intentionally and substantially modifies an AI system for use by a deployer.

### Deployer
Any person doing business in Colorado that deploys a high-risk AI system.

### Algorithmic Discrimination
Any condition where the use of an AI system results in unlawful differential treatment or impact that disfavors an individual or group based on protected characteristics.

---

## Core Requirements

### For Developers of High-Risk AI Systems

#### 1. Reasonable Care Standard
- Use reasonable care to protect persons from known or reasonably foreseeable risks of algorithmic discrimination
- Implement appropriate safeguards during development process
- Consider potential discriminatory impacts during system design

#### 2. Impact Assessment Requirements
- Complete impact assessments for high-risk AI systems
- Document potential risks of algorithmic discrimination
- Identify and evaluate mitigation measures
- Update assessments when systems are materially modified

#### 3. Risk Management Program
- Establish governance and oversight mechanisms
- Implement testing and monitoring procedures
- Develop incident response protocols
- Maintain documentation of risk management activities

#### 4. Documentation and Disclosure
- Provide deployers with statements regarding:
  - System intended uses and known limitations
  - Data requirements and specifications
  - Monitoring and testing recommendations
  - Risk mitigation measures

### For Deployers of High-Risk AI Systems

#### 1. Reasonable Care in Deployment
- Use reasonable care when deploying high-risk AI systems
- Implement recommended monitoring and testing procedures
- Maintain human oversight mechanisms where appropriate

#### 2. Impact Assessment Requirements
- Complete deployment-specific impact assessments
- Evaluate system performance in intended use context
- Assess potential for algorithmic discrimination
- Update assessments annually or when systems are substantially modified

#### 3. Consumer Notice Requirements
- Provide clear and conspicuous notice when high-risk AI systems are used for consequential decisions
- Include information about:
  - Purpose and nature of AI system use
  - Contact information for inquiries
  - Appeal or redress processes where available

#### 4. Incident Reporting
- Report instances of algorithmic discrimination to the Colorado Attorney General
- Provide required documentation and remediation plans
- Cooperate with investigations and enforcement actions

---

## Risk Management Framework

### Impact Assessment Components

Impact assessments must include:

1. **System Description**
   - Purpose and intended use cases
   - Data inputs and processing methods
   - Decision-making logic and outputs

2. **Stakeholder Impact Analysis**
   - Identification of affected populations
   - Assessment of potential discriminatory impacts
   - Evaluation of benefits and risks

3. **Bias and Fairness Evaluation**
   - Testing for discriminatory outcomes
   - Analysis across protected characteristics
   - Validation of fairness metrics

4. **Mitigation Strategies**
   - Technical safeguards and controls
   - Procedural oversight mechanisms
   - Monitoring and adjustment protocols

5. **Governance and Accountability**
   - Roles and responsibilities
   - Oversight and review processes
   - Documentation and reporting procedures

### Performance Monitoring Requirements

Ongoing monitoring must address:
- System accuracy and reliability
- Discriminatory outcome detection
- Performance across demographic groups
- Effectiveness of mitigation measures

---

## Consumer Protections

### Notice and Transparency Rights
- Right to know when AI systems affect consequential decisions
- Access to information about AI system purpose and operation
- Clear disclosure of automated decision-making processes

### Appeal and Redress Mechanisms
- Right to appeal or request review of AI-assisted decisions
- Access to human review where technically feasible
- Correction of erroneous or discriminatory outcomes

### Data Rights and Privacy
- Protection of personal information used in AI systems
- Limits on data collection and processing
- Security safeguards for sensitive data

---

## Enforcement and Compliance

### Attorney General Authority
The Colorado Attorney General has exclusive enforcement authority, including:
- Investigation of potential violations
- Issuance of civil penalties
- Injunctive relief to stop harmful practices
- Consent agreements and settlement authority

### Civil Penalties
- **Developers:** Up to $500,000 per violation for substantial non-compliance
- **Deployers:** Up to $50,000 per violation for substantial non-compliance
- Factors considered: harm caused, intent, compliance history, cooperation

### Affirmative Defenses
Entities may assert defenses based on:
- Compliance with relevant industry standards
- Adherence to federal regulatory requirements
- Implementation of reasonable safeguards and controls
- Good faith efforts to prevent discrimination

---

## Implementation Timeline

### Effective Date: February 1, 2026

#### Pre-Implementation Requirements (Before Feb 1, 2026)
- Complete initial impact assessments
- Establish risk management programs
- Develop consumer notice procedures
- Train personnel on compliance requirements

#### Ongoing Compliance Obligations (After Feb 1, 2026)
- Annual impact assessment updates
- Continuous monitoring and testing
- Incident reporting as required
- Consumer notice for all covered decisions

#### Regulatory Guidance Development
- Attorney General to issue implementing regulations
- Industry guidance on compliance best practices
- Safe harbor provisions for certain compliance activities
- Coordination with federal regulatory developments

---

## Multi-Jurisdictional Considerations

### Federal Law Interaction
- Coordination with federal AI regulatory initiatives
- Compliance with existing federal anti-discrimination laws
- Alignment with sectoral regulatory requirements (EEOC, FTC, etc.)

### Interstate Commerce Implications
- Application to AI systems used across state lines
- Coordination with other state AI regulations
- Considerations for national AI system deployments

### Industry-Specific Applications
- Integration with existing sectoral regulations
- Special considerations for healthcare, financial services, education
- Coordination with professional licensing and certification requirements

---

## Implementation Recommendations

### Immediate Actions (Now - February 2026)
1. **Legal and Regulatory Analysis**
   - Determine applicability to current AI systems
   - Assess overlap with existing compliance programs
   - Identify high-risk AI system inventory

2. **Risk Assessment Framework**
   - Develop impact assessment templates and procedures
   - Establish risk evaluation criteria and metrics
   - Create decision-making frameworks for AI system classification

3. **Governance Structure Development**
   - Define roles and responsibilities for compliance
   - Establish oversight and review processes
   - Create incident response and reporting procedures

### Medium-Term Implementation (2026-2027)
1. **Technical Compliance Measures**
   - Implement bias detection and monitoring tools
   - Develop fairness testing methodologies
   - Establish ongoing performance monitoring systems

2. **Consumer Interface Development**
   - Create notice and disclosure mechanisms
   - Develop appeal and redress procedures
   - Train customer service personnel on AI disclosures

3. **Documentation and Reporting Systems**
   - Establish comprehensive record-keeping procedures
   - Create audit trails for AI system decisions
   - Develop regulatory reporting capabilities

### Long-Term Compliance (2027+)
1. **Continuous Improvement**
   - Regular review and update of risk assessments
   - Enhancement of bias detection capabilities
   - Integration with emerging technical standards

2. **Industry Collaboration**
   - Participation in industry best practice development
   - Coordination with other state regulatory initiatives
   - Engagement with federal regulatory developments

---

## Related Resources

### Official Sources
- **Full Text:** [Colorado SB24-205](https://leg.colorado.gov/bills/sb24-205)
- **Legislative History:** Colorado General Assembly records
- **Attorney General Guidance:** [To be published]

### Implementation Support
- **Industry Associations:** AI governance and ethics organizations
- **Technical Standards:** NIST AI RMF, ISO/IEC 42001, IEEE standards
- **Legal Analysis:** Colorado Bar Association resources

### Cross-Reference Materials
- **Federal Coordination:** NIST AI RMF, OMB M-24-10
- **Multi-State Analysis:** NYC Local Law 144, California ADMT regulations
- **International Comparison:** EU AI Act, UK AI governance approach

---

**Document Control:**
- **Document Owner:** CIAF US State Regulatory Team
- **Next Review Date:** February 1, 2026 (Implementation Date)
- **Related Documents:** US Federal AI regulations, Multi-state compliance framework
- **Version History:** v1.0 - Initial summary (October 18, 2025)