# EU AI Act Risk Assessment Matrix

**Document Version:** 1.0  
**Date:** October 18, 2025  
**Regulation:** EU Artificial Intelligence Act (Regulation (EU) 2024/1689)  
**Assessment Scope:** EU market AI system compliance risks  
**Review Frequency:** Quarterly  

---

## Executive Summary

The EU AI Act represents the world's first comprehensive AI regulation with significant compliance obligations for AI providers, deployers, importers, and distributors in the EU market. This risk matrix identifies specific compliance risks with financial exposure up to €35 million or 7% of global annual turnover.

### Critical Risk Highlights
- **Maximum Financial Exposure:** €35M or 7% global turnover for prohibited use violations
- **Market Access Risk:** CE marking requirements for high-risk systems by August 2026
- **Timeline Pressure:** Multiple overlapping compliance deadlines from February 2025 to August 2027
- **Technical Complexity:** Comprehensive QMS, documentation, and conformity assessment requirements

---

## EU AI Act Risk Classification

### Risk Scoring Framework
- **Likelihood:** 1 (Very Low) to 5 (Very High) - based on regulatory enforcement patterns
- **Impact:** 1 (Minor) to 5 (Severe) - based on financial and operational consequences
- **Risk Score:** Likelihood × Impact (1-25 scale)

### EU-Specific Impact Definitions
1. **Minor (1):** Administrative warnings, minor operational adjustments
2. **Low (2):** Small fines (<€1M), limited market access restrictions
3. **Medium (3):** Moderate fines (€1M-€10M), temporary market suspension
4. **High (4):** Large fines (€10M-€100M), significant market access restrictions
5. **Severe (5):** Maximum fines (€35M or 7% revenue), market exclusion, criminal liability

---

## EU AI Act Compliance Risk Matrix

| **Risk Category** | **Specific Risk** | **EU AI Act Article** | **Likelihood** | **Impact** | **Risk Score** | **Financial Exposure** |
|---|---|---|---|---|---|---|
| **PROHIBITED PRACTICES** | Deploying banned AI systems | Article 5 | 2 | 5 | **25** | €35M or 7% turnover |
| **HIGH-RISK MISCLASSIFICATION** | Incorrect risk level assessment | Annex III, Article 6 | 4 | 4 | **20** | €15M or 3% turnover |
| **CE MARKING VIOLATIONS** | Non-compliant market placement | Article 48 | 4 | 4 | **20** | €15M or 3% turnover |
| **QMS IMPLEMENTATION** | Inadequate quality management | Article 17 | 4 | 3 | **18** | €15M or 3% turnover |
| **CONFORMITY ASSESSMENT** | Failed certification procedures | Article 43 | 3 | 4 | **18** | Market access denial |
| **GPAI TRANSPARENCY** | GPAI model documentation gaps | Article 53 | 4 | 3 | **18** | €15M or 3% turnover |
| **SYSTEMIC RISK MODELS** | GPAI systemic risk violations | Article 55 | 3 | 5 | **18** | €35M or 7% turnover |
| **TECHNICAL DOCUMENTATION** | Incomplete system documentation | Article 11 | 4 | 3 | **15** | €15M or 3% turnover |
| **DATA GOVERNANCE** | Non-compliant training data | Article 10 | 4 | 3 | **15** | €15M or 3% turnover |
| **HUMAN OVERSIGHT** | Inadequate human control | Article 14 | 3 | 3 | **15** | €15M or 3% turnover |
| **LOGGING REQUIREMENTS** | Insufficient audit trails | Article 12 | 4 | 2 | **15** | €15M or 3% turnover |
| **RISK MANAGEMENT** | Deficient risk management system | Article 9 | 3 | 3 | **12** | €15M or 3% turnover |
| **PERFORMANCE MONITORING** | Inadequate post-market monitoring | Article 72 | 3 | 3 | **12** | €15M or 3% turnover |
| **FRIA REQUIREMENTS** | Missing fundamental rights assessment | Article 27 | 3 | 3 | **12** | Administrative action |
| **PROVIDER OBLIGATIONS** | General provider duty violations | Article 16 | 3 | 2 | **12** | €15M or 3% turnover |
| **DEPLOYER OBLIGATIONS** | Deployer duty violations | Article 26 | 3 | 2 | **12** | Administrative action |
| **TRANSPARENCY OBLIGATIONS** | Limited risk system disclosure gaps | Article 50 | 4 | 1 | **10** | €7.5M or 1.5% turnover |
| **AI LITERACY** | Insufficient user training | Article 4 | 3 | 2 | **10** | Administrative warnings |
| **INCIDENT REPORTING** | Failure to report serious incidents | Article 73 | 2 | 3 | **8** | Administrative action |
| **AUTHORIZED REPRESENTATIVE** | Missing EU representative | Article 25 | 3 | 1 | **6** | Administrative warnings |

---

## Prohibited AI Practices - Critical Risk Analysis

### Article 5 Banned Practices (Risk Score: 25)

#### Subliminal Techniques and Manipulation
- **Risk:** AI systems using subliminal techniques materially distorting behavior
- **Exposure:** €35M or 7% global turnover + criminal liability
- **Examples:** Dark patterns, psychological manipulation, behavioral nudging
- **Mitigation:** Comprehensive use case review, behavioral impact assessments

#### Exploitation of Vulnerabilities
- **Risk:** AI exploiting vulnerabilities of vulnerable groups (children, disabled, economically disadvantaged)
- **Exposure:** €35M or 7% global turnover + civil liability
- **Examples:** Predatory lending algorithms, manipulative advertising to children
- **Mitigation:** Vulnerable population impact assessments, ethical review boards

#### Social Scoring Systems
- **Risk:** Comprehensive social scoring with cross-context detrimental effects
- **Exposure:** €35M or 7% global turnover
- **Examples:** Credit-social behavior linkage, cross-platform reputation systems
- **Mitigation:** Context-specific scoring, transparent criteria, user control

#### Biometric Categorization
- **Risk:** Inferring sensitive attributes from biometric data
- **Exposure:** €35M or 7% global turnover
- **Examples:** Race detection, sexual orientation inference, political affiliation
- **Mitigation:** Biometric data minimization, purpose limitation, consent mechanisms

#### Real-Time Biometric Identification
- **Risk:** Untargeted surveillance in publicly accessible spaces
- **Exposure:** €35M or 7% global turnover + criminal liability
- **Examples:** Mass surveillance systems, crowd monitoring without consent
- **Mitigation:** Targeted use cases only, judicial authorization, proportionality

---

## High-Risk AI System Requirements

### Classification Requirements (Annex III)

#### Employment and Workers Management
- **Risk Areas:** Recruitment, performance evaluation, promotion decisions, termination
- **Compliance Requirements:** Full QMS, technical documentation, CE marking
- **Timeline:** August 2, 2026
- **Mitigation:** Bias testing, human oversight, appeal mechanisms

#### Access to Essential Services
- **Risk Areas:** Credit scoring, insurance underwriting, healthcare access, education enrollment
- **Compliance Requirements:** Full QMS, conformity assessment, fundamental rights assessment
- **Timeline:** August 2, 2026
- **Mitigation:** Fairness testing, alternative access mechanisms, human review

#### Law Enforcement and Justice
- **Risk Areas:** Risk assessments, evidence evaluation, case management
- **Compliance Requirements:** Enhanced oversight, fundamental rights assessment
- **Timeline:** August 2, 2026
- **Mitigation:** Judicial oversight, transparency requirements, accuracy testing

#### Migration and Border Control
- **Risk Areas:** Visa applications, border security, asylum decisions
- **Compliance Requirements:** Fundamental rights assessment, human oversight
- **Timeline:** August 2, 2026
- **Mitigation:** Due process protections, appeal mechanisms, accuracy requirements

### Quality Management System (Article 17)

#### Core QMS Requirements
1. **Quality Policy:** AI governance strategy and commitment
2. **Organizational Structure:** Roles, responsibilities, competencies
3. **Data Management:** Collection, processing, training dataset governance
4. **Design and Development:** AI system lifecycle procedures
5. **Documentation Control:** Technical documentation management
6. **Risk Management:** Comprehensive risk identification and mitigation
7. **Supplier Management:** Vendor and component oversight
8. **Corrective Actions:** Non-conformity and improvement procedures
9. **Internal Audits:** Regular QMS effectiveness assessments

#### Implementation Timeline
- **Phase 1 (Q1 2025):** QMS framework development and documentation
- **Phase 2 (Q2-Q4 2025):** Process implementation and training
- **Phase 3 (Q1-Q2 2026):** Internal audits and process optimization
- **Phase 4 (Q3 2026):** Conformity assessment preparation
- **Phase 5 (Q4 2026):** CE marking and market placement

---

## General-Purpose AI Model Requirements

### GPAI Transparency Obligations (Article 53)

#### Documentation Requirements
- **Technical Documentation:** Model architecture, training methodology, datasets
- **Use Instructions:** Capabilities, limitations, suitable applications
- **Model Cards:** Standardized information format for transparency
- **Compliance Timeline:** August 2, 2025

#### Risk Assessment
- **Likelihood:** 4 (High) - Complex technical requirements
- **Impact:** 3 (Medium) - €15M or 3% turnover exposure
- **Mitigation:** Automated documentation tools, standardized templates

### Systemic Risk Models (Article 55)

#### Classification Threshold
- **Computational Threshold:** 10^25 floating point operations for training
- **Alternative Metrics:** High-impact capabilities assessment
- **Timeline:** August 2, 2025

#### Enhanced Obligations
- **Model Evaluation:** Systemic risk assessment and testing
- **Adversarial Testing:** Red teaming and cybersecurity evaluation
- **Incident Reporting:** Serious incident notification procedures
- **Risk Mitigation:** Technical measures to reduce systemic risks

#### Risk Assessment
- **Likelihood:** 3 (Medium) - Limited number of qualifying models
- **Impact:** 5 (Severe) - €35M or 7% turnover exposure
- **Mitigation:** Early identification, comprehensive testing, risk mitigation

---

## Conformity Assessment and CE Marking

### Conformity Assessment Routes

#### Internal Control (Annex VI)
- **Applicable Systems:** Self-assessment for most high-risk AI
- **Requirements:** Technical documentation, QMS implementation, declaration of conformity
- **Timeline:** System-specific assessment before market placement
- **Risk:** Documentation inadequacy, assessment errors

#### Notified Body Assessment (Annex VII)
- **Applicable Systems:** Biometric identification, critical infrastructure
- **Requirements:** Third-party conformity assessment, ongoing surveillance
- **Timeline:** Extended assessment periods, higher costs
- **Risk:** Assessment delays, rejection, ongoing monitoring failures

### CE Marking Requirements

#### Marking Obligations
- **Placement:** Visible on AI system or documentation
- **Declaration:** Conformity declaration availability
- **Identification:** Provider identification and traceability
- **Timeline:** Before market placement (August 2026+)

#### Risk Factors
- **Documentation Gaps:** Incomplete technical files
- **Assessment Errors:** Incorrect conformity evaluation
- **Market Surveillance:** Post-market authority inspections
- **International Recognition:** CE marking acceptance outside EU

---

## Enforcement and Penalties

### Administrative Penalties Structure

| **Violation Category** | **Maximum Fine** | **Calculation Basis** | **Examples** |
|---|---|---|---|
| **Prohibited Practices** | €35M or 7% turnover | Higher amount applies | Social scoring, manipulation |
| **Systemic Risk Models** | €35M or 7% turnover | Higher amount applies | GPAI systemic risk violations |
| **High-Risk Violations** | €15M or 3% turnover | Higher amount applies | QMS, documentation, CE marking |
| **Information Obligations** | €7.5M or 1.5% turnover | Higher amount applies | Transparency, reporting gaps |

### Enforcement Authorities

#### National Competent Authorities
- **Designation:** EU member state regulatory bodies
- **Powers:** Investigation, penalty imposition, market surveillance
- **Coordination:** European AI Board oversight and guidance

#### Market Surveillance
- **Post-Market Monitoring:** Ongoing compliance verification
- **Incident Investigation:** Serious incident follow-up
- **Corrective Measures:** System withdrawal, modification requirements

---

## Timeline-Specific Risk Analysis

### February 2, 2025 - Prohibited Uses (Risk Score: 25)
**Requirements:**
- Immediate cessation of prohibited AI practices
- AI literacy programs for public sector deployers
- Legal compliance verification across all AI systems

**Risk Factors:**
- Limited preparation time for complex systems
- Unclear boundary definitions requiring legal interpretation
- Potential criminal liability for continued violations

**Mitigation Actions:**
1. **Immediate:** Comprehensive prohibited use audit
2. **Technical:** System modification or deactivation
3. **Legal:** Specialized counsel engagement for boundary cases
4. **Process:** Prohibited use monitoring and prevention procedures

### August 2, 2025 - GPAI Obligations (Risk Score: 18)
**Requirements:**
- GPAI model transparency documentation
- Systemic risk model additional obligations
- Technical documentation standardization

**Risk Factors:**
- Complex technical documentation requirements
- Systemic risk assessment methodology uncertainty
- Limited regulatory guidance availability

**Mitigation Actions:**
1. **Assessment:** GPAI model inventory and classification
2. **Documentation:** Technical documentation template development
3. **Testing:** Systemic risk evaluation procedures
4. **Compliance:** Ongoing monitoring and reporting systems

### August 2, 2026 - High-Risk Systems (Risk Score: 20)
**Requirements:**
- Full QMS implementation and certification
- Technical documentation completion
- Conformity assessment and CE marking
- Risk management system operationalization

**Risk Factors:**
- Complex QMS implementation across organization
- Notified body capacity constraints
- Technical documentation comprehensiveness
- Conformity assessment procedural complexity

**Mitigation Actions:**
1. **Early Start:** QMS development beginning Q1 2025
2. **Resource Allocation:** Dedicated compliance team and budget
3. **External Support:** Specialized consultants and legal counsel
4. **Testing:** Pilot conformity assessments for critical systems

---

## Sector-Specific Risk Considerations

### Financial Services
- **Enhanced Scrutiny:** Credit scoring, risk assessment algorithms
- **Regulatory Overlap:** EU financial regulations (MiFID II, GDPR)
- **Risk Multiplier:** 2x base risk due to systemic importance
- **Mitigation:** Integrated compliance with financial regulators

### Healthcare
- **Medical Device Overlap:** EU MDR/IVDR compliance requirements
- **Patient Safety:** Enhanced risk management and clinical evaluation
- **Risk Multiplier:** 2.5x base risk due to safety implications
- **Mitigation:** Medical device regulatory expertise, clinical validation

### Employment and HR
- **Discrimination Law:** EU anti-discrimination directive compliance
- **Works Council:** Employee representative consultation requirements
- **Risk Multiplier:** 2x base risk due to discrimination exposure
- **Mitigation:** Bias testing, employee engagement, legal review

### Public Sector
- **FRIA Requirements:** Mandatory fundamental rights assessments
- **Transparency:** Enhanced public disclosure obligations
- **Risk Multiplier:** 1.5x base risk due to public scrutiny
- **Mitigation:** Public consultation, transparency reporting, oversight

---

## Technical Implementation Guidance

### Data Governance (Article 10)

#### Training Dataset Requirements
- **Relevance and Representativeness:** Dataset appropriateness for intended use
- **Completeness and Accuracy:** Data quality and error identification
- **Bias Assessment:** Statistical bias evaluation and mitigation
- **Documentation:** Dataset provenance and characteristics recording

#### Implementation Steps
1. **Data Inventory:** Comprehensive training dataset catalog
2. **Quality Assessment:** Statistical quality and bias evaluation
3. **Governance Framework:** Data lifecycle management procedures
4. **Monitoring:** Ongoing data quality and bias monitoring

### Human Oversight (Article 14)

#### Design Requirements
- **Full Understanding:** Humans must understand system capabilities and limitations
- **Awareness Maintenance:** Ongoing situational awareness preservation
- **Interpretation Ability:** Output interpretation and assessment capability
- **Intervention Authority:** Ability to override or interrupt system operation

#### Implementation Approaches
- **Human-in-the-Loop:** Direct human participation in decision process
- **Human-on-the-Loop:** Human oversight with intervention capability
- **Human-in-Command:** Overall human responsibility and control
- **Risk-Based Approach:** Oversight intensity based on risk assessment

### Logging and Record-Keeping (Article 12)

#### Automatic Logging Requirements
- **Operation Period:** Comprehensive activity logging during operation
- **Input Data:** Input data logging to extent relevant for risk management
- **Decision Process:** Decision-making process and logic recording
- **Human Oversight:** Human intervention and oversight activity logging

#### Technical Implementation
- **Immutable Logs:** Tamper-proof logging infrastructure
- **Data Retention:** Appropriate retention periods for different log types
- **Access Controls:** Secure access to log data for authorized personnel
- **Integration:** Logging integration with overall system architecture

---

## Vendor and Supply Chain Risk Management

### Provider Chain Responsibilities

#### AI System Providers
- **Primary Responsibility:** Full EU AI Act compliance
- **QMS Implementation:** Comprehensive quality management system
- **CE Marking:** Conformity assessment and market placement
- **Liability:** Primary legal and financial responsibility

#### Component Providers
- **Limited Scope:** Specific component compliance requirements
- **Documentation:** Component specification and limitation documentation
- **Integration Support:** Assistance with system-level compliance
- **Liability:** Component-specific liability allocation

#### Cloud and Infrastructure Providers
- **Infrastructure Compliance:** Underlying infrastructure security and availability
- **Data Processing:** GDPR compliance for data processing activities
- **Service Level:** Availability and performance guarantees
- **Liability:** Infrastructure failure and data processing liability

### Vendor Due Diligence Framework

#### High-Risk Vendor Assessment
- **EU AI Act Compliance:** Comprehensive compliance verification
- **QMS Certification:** Quality management system validation
- **Technical Capability:** Ability to meet technical requirements
- **Financial Stability:** Ongoing viability and support capability

#### Contractual Risk Allocation
- **Compliance Warranties:** Vendor compliance guarantees and representations
- **Indemnification:** Financial protection for compliance failures
- **Audit Rights:** Ongoing compliance monitoring and verification
- **Termination Rights:** Ability to terminate for compliance failures

---

## Conclusion and Recommendations

### Priority Risk Mitigation

#### Immediate Actions (Q4 2024 - Q1 2025)
1. **Prohibited Use Audit:** Comprehensive review and elimination of banned practices
2. **Legal Counsel:** Specialized EU AI Act legal expertise engagement
3. **Compliance Team:** Dedicated EU AI Act compliance organization
4. **Budget Allocation:** $2-5M initial investment for compliance infrastructure

#### Medium-Term Implementation (Q2 2025 - Q2 2026)
1. **QMS Development:** Comprehensive quality management system implementation
2. **Technical Documentation:** Complete technical file development for high-risk systems
3. **Conformity Assessment:** Preparation for notified body assessment where required
4. **Training Programs:** Organization-wide EU AI Act compliance training

#### Long-Term Optimization (Q3 2026+)
1. **CE Marking:** Successful market placement with compliant systems
2. **Continuous Monitoring:** Ongoing compliance monitoring and optimization
3. **Competitive Advantage:** Leverage compliance capabilities for market differentiation
4. **Innovation Focus:** Compliance-driven innovation and development

### Success Metrics

- **Compliance Rate:** 100% of high-risk systems compliant by August 2026
- **Penalty Avoidance:** Zero significant EU AI Act violations
- **Market Access:** Maintained or expanded EU market presence
- **Cost Optimization:** Compliance costs <1.5% of EU revenue

### Strategic Recommendations

1. **Executive Commitment:** Board-level sponsorship and resource allocation
2. **Early Investment:** Front-load compliance investment for competitive advantage
3. **Regulatory Engagement:** Active participation in EU AI Act implementation
4. **Innovation Integration:** Embed compliance into innovation and development processes
5. **Ecosystem Collaboration:** Partner with compliance vendors and certification bodies

The EU AI Act represents the most comprehensive AI regulation globally. Organizations that invest early and comprehensively in compliance will not only avoid significant penalties but will establish sustainable competitive advantages in the world's largest AI regulatory market.

---

**Document Control:**
- **Document Owner:** CIAF EU Compliance Team
- **Review Frequency:** Quarterly with regulatory update triggers
- **Next Review Date:** January 18, 2026
- **Related Documents:** EU AI Act technical guidance, QMS implementation guides
- **Version History:** v1.0 - Initial comprehensive assessment (October 18, 2025)